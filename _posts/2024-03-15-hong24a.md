---
abstract: The structure of RNA can determine the function, and improvements in RNA
  secondary structure prediction can help in understanding the functions of RNA. Nucleotides
  in RNA sequences form base-pairing interactions in context-specific preferential
  behavior to help determine the secondary structure. Structure prediction algorithms
  have been developed to predict the secondary structure, including dynamic programming,
  and machine learning approaches. One of the central challenges in the prediction
  of secondary structure with deep learning is that these architectures are not good
  at bracketed structure prediction. To overcome this challenge, we present a deep
  learning approach for predicting secondary structure that uses an input predicted
  structure to provide a scaffolding for the structure prediction. We find that architectures
  using LSTM and  self-attention-based transformer layers predict a strong baseline
  in the prediction of base pairs (F1=53.73), but significantly improves (F1=59.52)
  when predictions from dynamic programming methods are provided as input. Model interpretation
  shows that patterns of attention for different layers of the network are enriched
  for specific paired regions or regions that should be paired. Analysis of neural
  network models like this can shed light on possible missed interactions, and what
  other positions contribute most to output fixed positions.
title: Improving transformer secondary structure predictions with secondary structure
  ”fixing” task
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hong24a
month: 0
tex_title: Improving transformer secondary structure predictions with secondary structure
  ”fixing” task
firstpage: 267
lastpage: 278
page: 267-278
order: 267
cycles: false
bibtex_author: Hong, Juneki and Deng, Dezhong and Hendrix, David A.
author:
- given: Juneki
  family: Hong
- given: Dezhong
  family: Deng
- given: David A.
  family: Hendrix
date: 2024-03-15
address:
container-title: Proceedings of the 18th Machine Learning in Computational Biology
  meeting
volume: '240'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 3
  - 15
pdf: https://proceedings.mlr.press/v240/hong24a/hong24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
